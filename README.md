# Triton-Ascend 高性能矩阵乘法算子

## 项目介绍

本项目基于 Triton 框架，针对 Ascend NPU 硬件特性，实现高性能矩阵乘法算子优化。核心目标是解决 Ascend NPU 片上缓存有限、访存延迟等瓶颈，通过并行化改造、参数调优、特定矩阵适配等策略，显著提升矩阵乘法计算效率，尤其适配大尺寸矩阵及长瘦型特殊矩阵场景。

### 核心背景

Ascend NPU 上的矩阵乘法需依赖分块技术（Tiling），将全局内存（GM）中的大型矩阵切割为子矩阵，通过「GM→二级缓存→一级缓存」的数据流适配硬件存储。传统实现存在串行计算瓶颈、参数依赖强、特殊矩阵适配不足等问题，本项目通过针对性优化突破这些限制。

## 核心功能

1. **K 维度并行计算**：将矩阵乘法公共维度 K 的串行迭代改造为并行执行，通过多线程分配子任务提升并行度。
2. **智能参数调优**：通过实验确定最优循环展开因子（S_UNROLL）和并行写回分块数，平衡延迟隐藏与资源占用。
3. **长瘦矩阵适配**：针对长瘦矩阵（如 M>>N 或 N>>M）设计非对称分块策略，优化长维度并行效率，抑制短维度调度开销。
4. **并行写回优化**：利用 Ascend NPU 向量核特性，实现结果矩阵的多子块并行写回，提升内存带宽利用率。
5. **Autotune 自动调优**：集成 Triton Autotune 机制，自动匹配输入形状与硬件环境的最优分块参数。

## 快速开始

### 环境依赖

- 硬件：Ascend NPU（支持 Triton 框架适配）

- 软件：

  - Python 3.8+
  - Triton 2.0+
  - PyTorch 1.18+
  - torch_npu（Ascend PyTorch 适配库）
  - pandas（性能测试统计）

### 安装步骤

1. 安装 Ascend NPU 驱动及基础软件栈（参考 [华为官方文档](https://www.hiascend.com/document)）

2. 安装依赖包：

   ```
   pip install triton torch torch_npu pandas
   ```

3. 克隆本项目代码并进入目录：

   ```
   git clone <项目仓库地址>
   cd triton-ascend-matmul
   ```

### 简单使用示例

```
import torch
import torch_npu
from matmul_kernel import matmul_wrapper, KERNEL_V4_KPAR

# 配置 Ascend NPU 设备
torch.npu.set_device(0)

# 生成测试矩阵（支持方阵、矩形、长瘦矩阵）
a = torch.randn((4096, 4096), dtype=torch.float16, device="npu")
b = torch.randn((4096, 4096), dtype=torch.float16, device="npu")

# 调用优化后的矩阵乘法算子
c = matmul_wrapper(a, b, kernel_func=KERNEL_V4_KPAR)

# 验证结果（与 PyTorch 原生实现对比）
c_torch = torch.matmul(a, b)
print(f"结果误差: {(c - c_torch).abs().max().item()}")
```



## 详细使用说明

### 核心 API

|                           函数名                            |      功能描述      |                           参数说明                           |
| :---------------------------------------------------------: | :----------------: | :----------------------------------------------------------: |
|             `matmul_wrapper(a, b, kernel_func)`             |  矩阵乘法入口函数  | `a/b`: 输入矩阵（支持 float16）；`kernel_func`: 选择的优化核（默认提供 `KERNEL_V4_KPAR`） |
| `create_kernel(name, autotune_configs, parallel, k_splits)` | 动态创建自定义算子 | `parallel`: 是否启用并行写回；`k_splits`: K 维度并行拆分次数（当前最大支持 2） |

### 支持的矩阵形状

- 方阵：512x512x512、2048x2048x2048、4096x4096x4096
- 矩形矩阵：2048x1024x4096、4096x4096x1024
- 长瘦矩阵：4096x32x4096、2048x32x2048 等（M/N 维度差异显著）

### 参数配置

|    参数名    |        作用        | 最优值 |                            说明                            |
| :----------: | :----------------: | :----: | :--------------------------------------------------------: |
|  `S_UNROLL`  |    循环展开因子    |   8    | 平衡指令并行与资源占用，过小无法掩盖延迟，过大导致资源溢出 |
| `写回分块数` |  并行写回子块数量  |   4    |    适配 Ascend NPU 4 个并行处理单元，提升内存带宽利用率    |
|  `K_SPLITS`  | K 维度并行拆分次数 |   2    |               当前受硬件容量限制，最大支持 2               |

## 优化细节

### 1. 串行→并行改造

- **核心逻辑**：将 K 维度迭代任务按 `K_SPLITS` 拆分到多个线程，通过 `tl.program_id(2)` 分配线程 ID，实现多线程并行处理不同 K 子块。
- **循环展开**：通过 `S_UNROLL=8` 展开内层循环，减少循环控制开销，提升硬件流水线利用率。

### 2. 参数调优原理

- **S_UNROLL=8**：既提供足够独立指令覆盖访存延迟，又不超出寄存器与调度资源上限。
- **写回分块数 = 4**：避免过多分块导致的调度开销与内存冲突，充分利用 NPU 并行写回能力。

### 3. 长瘦矩阵优化策略

- 优先优化长维度（M/N）的并行效率与缓存利用率。
- 短维度采用小分块、少并行，抑制线程调度开销。
- 通过打包计算、分块调整提升短维度向量资源利用率。

## 性能表现

### 提速比对比（优化后 V4 / 原始 V1）

|    矩阵形状    | 提速比 |                 说明                 |
| :------------: | :----: | :----------------------------------: |
|  512x512x512   | 0.84x  | 小矩阵并行开销大于收益，性能略有下滑 |
| 2048x2048x2048 | 1.13x  |         中等矩阵性能稳步提升         |
| 4096x4096x4096 | 1.22x  |     大矩阵提速显著，峰值达 2.31x     |
| 2048x1024x4096 | 1.28x  |         矩形矩阵优化效果明显         |
|  4096x32x4096  | 1.79x  |         长瘦矩阵适配策略生效         |

### 关键结论

- 大尺寸矩阵（≥2048x2048）和长瘦矩阵能获得显著性能提升，充分利用并行计算与内存带宽。
- 小尺寸矩阵（≤512x512）因并行任务调度开销，性能可能略有下降，建议优先使用原生实现。

## 项目亮点与不足

### 亮点

1. 实现 K 维度并行计算，突破串行迭代瓶颈，大幅提升并行度。
2. 通过对比实验确定最优参数组合，兼顾通用性与硬件适配性。
3. 针对长瘦矩阵设计非对称优化策略，拓展算子适用场景。

### 不足

1. `K_SPLITS` 受硬件容量限制，当前最大值仅支持 2，无法充分发挥多线程潜力。
2. 优化策略以现有技术改进为主，缺乏创新性矩阵乘法优化算法。
3. 小矩阵并行化收益不足，未解决调度开销与缓存局部性破坏问题。

## 未来计划

1. 突破 `K_SPLITS` 限制，探索更高维度的并行拆分方案。
2. 针对小矩阵设计轻量化并行策略，平衡开销与收益。
3. 研究创新型分块算法与硬件协同优化，进一步提升性能上限。
4. 扩展算子支持更多数据类型（如 float32、bfloat16）和激活函数。

## 团队信息

- 小组成员：王淇辉、袁谦朗、何熙然、娄彦轩
- 项目定位：Ascend NPU 高性能计算优化实践，聚焦矩阵乘法算子性能提升

## 致谢

感谢 Triton 框架生态与 Ascend NPU 硬件支持，本项目基于开源技术与硬件特性进行优化，欢迎交流与贡献代码！
